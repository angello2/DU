{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acba18f5",
   "metadata": {},
   "source": [
    "# Zadatak 1. Učitavanje podataka (25% bodova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8d79080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prvi\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e2565c",
   "metadata": {},
   "source": [
    "Sve metode potrebne za prvi zadatak nalaze se u datoteci prvi.py. U sljedećem isječku koda računamo frekvencije pojavljivanja riječi, stvaramo vokabulare i učitavamo dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acfd624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_data, freq_label = prvi.get_frequencies('data/sst_train_raw.csv')\n",
    "text_vocab = prvi.Vocab(freq_data, max_size=-1, min_freq=1)\n",
    "label_vocab = prvi.Vocab(freq_label, use_extra=False)\n",
    "train_dataset = prvi.NLPDataset('data/sst_train_raw.csv', text_vocab, label_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd348ec",
   "metadata": {},
   "source": [
    "## Razred Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e21cb00",
   "metadata": {},
   "source": [
    "Vaša implementacija razreda Vocab mora implementirati funkcionalnost pretvorbe niza tokena (ili jednog tokena) u brojeve. Ovu funkciju možete nazvati encode. Primjer ove pretvorbe za četvrtu instancu train skupa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4248ad2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: ['yet', 'the', 'act', 'is', 'still', 'charming', 'here']\n",
      "Label: positive\n",
      "Numericalized text: tensor([189,   2, 674,   7, 129, 348, 143])\n",
      "Numericalized label: tensor([0])\n"
     ]
    }
   ],
   "source": [
    "instance_text, instance_label = train_dataset.instances[3]\n",
    "print(f\"Text: {instance_text}\")\n",
    "print(f\"Label: {instance_label}\")\n",
    "print(f\"Numericalized text: {text_vocab.encode(instance_text)}\")\n",
    "print(f\"Numericalized label: {label_vocab.encode(instance_label)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d691360",
   "metadata": {},
   "source": [
    "Također, vaša implementacija razreda Vocab mora primati iduće parametre:\n",
    "\n",
    "max_size: maksimalni broj tokena koji se sprema u vokabular (uključuje i posebne znakove). -1 označava da se spremaju svi tokeni.\n",
    "min_freq: minimalna frekvencija koju token mora imati da bi ga se spremilo u vokabular (\\ge). Posebni znakovi ne prolaze ovu provjeru.\n",
    "Primjer izgradnje vokabulara sa svim tokenima (duljina uključuje i posebne znakove):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fa5adff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14806\n"
     ]
    }
   ],
   "source": [
    "text_vocab = prvi.Vocab(freq_data, max_size=-1, min_freq=0)\n",
    "print(len(text_vocab.itos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32bd474",
   "metadata": {},
   "source": [
    "## Učitavanje vektorskih reprezentacija"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f4693c",
   "metadata": {},
   "source": [
    "Vaš zadatak je implementirati funkciju koja će za zadani vokabular (iterable stringova) generirati embedding matricu. Vaša funkcija treba podržavati dva načina genriranja embedding matrice: nasumična inicijalizacija iz standardne normalne razdiobe (N(0,1)) i učitavanjem iz datoteke. Pri učitavanju iz datoteke, ako ne pronađete vektorsku reprezentaciju za neku riječ, inicijalizirajte ju normalno. Vektorsku reprezentaciju za znak punjenja (na indeksu 0) morate inicijalizirati na vektor nula. Jednostavan način na koji možete implementirati ovo učitavanje je da inicijalirate matricu iz standardne normalne razdiobe, a potom prebrišete inicijalnu reprezentaciju u retku za svaku riječ koju učitate. Bitno: Pripazite da redoslijed vektorskih reprezentacija u matrici odgovara redoslijedu riječi u vokabularu! Npr., na indeksu 0 mora biti reprezentacija za posebni znak punjenja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b18e40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14806, 300])\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = prvi.get_embedding_matrix(text_vocab, 300, 'data/sst_glove_6b_300d.txt')\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcc7633",
   "metadata": {},
   "source": [
    "Jednom kad ste uspješno učitali vašu V×d embedding matricu, iskoristite torch.nn.Embedding.from_pretrained() kako bi vašu matricu spremili u optimizirani omotač za vektorske reprezentacije. Postavite parametar funkcije padding_idx na 0 (indeks znaka punjenja u vašoj embedding matrici), a parametar funkcije freeze ostavite na True ako koristite predtrenirane reprezentacije, a postavite na False inače."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6181411",
   "metadata": {},
   "source": [
    "## Nadjačavanje metoda torch.utils.data.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d248c2d",
   "metadata": {},
   "source": [
    "Da bi naša implementacija razreda NLPDataset bila potpuna, potrebno je nadjačati __getitem__ metodu koja omogućava indeksiranje razreda. Za potrebe vježbe, ta metoda treba vraćati numerikalizirani text i labelu referencirane instance. Također, dovoljno je napraviti da se numerikalizacija radi “on-the-fly”, i nije ju nužno cachirati.\n",
    "\n",
    "Primjer numerikalizacije s nadjačavanjem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c94680c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: ['yet', 'the', 'act', 'is', 'still', 'charming', 'here']\n",
      "Label: positive\n",
      "Numericalized text: tensor([189,   2, 674,   7, 129, 348, 143])\n",
      "Numericalized label: tensor([0])\n"
     ]
    }
   ],
   "source": [
    "instance_text, instance_label = train_dataset.instances[3]\n",
    "print(f\"Text: {instance_text}\")\n",
    "print(f\"Label: {instance_label}\")\n",
    "numericalized_text, numericalized_label = train_dataset[3]\n",
    "print(f\"Numericalized text: {numericalized_text}\")\n",
    "print(f\"Numericalized label: {numericalized_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa87ca77",
   "metadata": {},
   "source": [
    "# Implementacija batchiranja podataka: collate funkcija"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c70ef3a",
   "metadata": {},
   "source": [
    "Zadatak naše collate funkcije biti će nadopuniti duljine instanci znakom punjenja do duljine najdulje instance u batchu. Za ovo, pogledajte funkciju from torch.nn.utils.rnn.pad_sequence. Primjetite da vaša implementacija collate funkcije mora znati koji se indeks koristi kao znak punjenja.\n",
    "\n",
    "Jednom kad smo implementirali sve navedeno, naše učitavanje podataka bi moglo izgledati ovako:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5676d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts: tensor([[   2,  554,    7, 2872,    6,   22,    2, 2873, 1236,    8,   96, 4800,\n",
      "            4,   10,   72,    8,  242,    6,   75,    3, 3576,   56, 3577,   34,\n",
      "         2022, 2874, 7123, 3578, 7124,   42,  779, 7125,    0,    0],\n",
      "        [   2, 2875, 2023, 4801,    5,    2, 3579,    5,    2, 2876, 4802,    7,\n",
      "           40,  829,   10,    3, 4803,    5,  627,   62,   27, 2877, 2024, 4804,\n",
      "          962,  715,    8, 7126,  555,    5, 7127, 4805,    8, 7128]])\n",
      "Labels: tensor([0, 0])\n",
      "Lengths: tensor([32, 34])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2 # Only for demonstrative purposes\n",
    "shuffle = False # Only for demonstrative purposes\n",
    "train_data_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, \n",
    "                              shuffle=shuffle, collate_fn=prvi.pad_collate_fn)\n",
    "texts, labels, lengths = next(iter(train_data_loader))\n",
    "print(f\"Texts: {texts}\")\n",
    "print(f\"Labels: {labels}\")\n",
    "print(f\"Lengths: {lengths}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca866a4",
   "metadata": {},
   "source": [
    "# Zadatak 2. Implementacija baseline modela (25% bodova)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bb6e91",
   "metadata": {},
   "source": [
    "Prvi korak kod svakog zadatka strojnog učenja bi trebao biti implementacija baseline modela. Baseline model nam služi za procjenu performansi koje naš stvarni, uobičajeno skuplji model mora moći preći kao plitak potok. Također, baseline modeli će nam pokazati kolika je stvarno cijena izvođenja naprednijih modela.\n",
    "\n",
    "Vaš zadatak u laboratorijskoj vježbi je implementirati model koji će koristiti sažimanje usrednjavanjem (eng. mean pooling) kako bi eliminirao problematičnu varijabilnu dimenziju. Pri primjeni sažimanja usrednjavanjem odmah eliminirajte cijelu vremensku dimenziju (tzv. okno je veličine T).\n",
    "\n",
    "Osnovni model koji implementirate mora izgledati ovako:\n",
    "\n",
    "    avg_pool() -> fc(300, 150) -> ReLU() -> fc(150, 150) -> ReLU() -> fc(150,1)\n",
    "    \n",
    "Kao gubitak predlažemo da koristite BCEWithLogitsLoss, u kojem slučaju ne morate primjeniti sigmoidu na izlaznim logitima. Alternativno, možete staviti da vam je izlazna dimenzionalnost broj klasa te koristiti gubitak unakrsne entropije. Oba pristupa su korištena u praksi ovisno o osobnim preferencama.\n",
    "\n",
    "Kao algoritam optimizacije koristite Adam.\n",
    "\n",
    "Implementirajte metrike praćenja performansi modela. Osim gubitka na skupu podataka, zanimaju nas preciznost (eng. accuracy), f1 mjera i matrica zabune (eng. confusion matrix). Nakon svake epohe ispišite performanse modela po svim metrikama na skupu za validaciju, a nakon zadnje epohe ispišite performanse modela na skupu za testiranje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f75bbe5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 results on validation dataset:\n",
      "Accuracy: 0.6068094453596925\n",
      "Precision: 0.5947775628626693\n",
      "F1 score: 0.6320657759506682\n",
      "Loss: 27.152376\n",
      "Confusion matrix:\n",
      " [[490 419]\n",
      " [297 615]]\n",
      "\n",
      "Epoch 2 results on validation dataset:\n",
      "Accuracy: 0.6370126304228446\n",
      "Precision: 0.6071733561058924\n",
      "F1 score: 0.6826692270763323\n",
      "Loss: 24.920431\n",
      "Confusion matrix:\n",
      " [[449 460]\n",
      " [201 711]]\n",
      "\n",
      "Epoch 3 results on validation dataset:\n",
      "Accuracy: 0.6523887973640856\n",
      "Precision: 0.6197424892703862\n",
      "F1 score: 0.6952335098700047\n",
      "Loss: 23.32166\n",
      "Confusion matrix:\n",
      " [[466 443]\n",
      " [190 722]]\n",
      "\n",
      "Epoch 4 results on validation dataset:\n",
      "Accuracy: 0.6633717737506865\n",
      "Precision: 0.6287683031869078\n",
      "F1 score: 0.7042932947419199\n",
      "Loss: 22.161985\n",
      "Confusion matrix:\n",
      " [[478 431]\n",
      " [182 730]]\n",
      "\n",
      "Epoch 5 results on validation dataset:\n",
      "Accuracy: 0.671609006040637\n",
      "Precision: 0.6297520661157024\n",
      "F1 score: 0.7181903864278982\n",
      "Loss: 22.034103\n",
      "Confusion matrix:\n",
      " [[461 448]\n",
      " [150 762]]\n",
      "\n",
      "Results on test dataset:\n",
      "Accuracy: 0.6548165137614679\n",
      "Precision: 0.6144144144144145\n",
      "F1 score: 0.693794506612411\n",
      "Loss: 20.450077\n",
      "Confusion matrix:\n",
      " [[230 214]\n",
      " [ 87 341]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import drugi\n",
    "import numpy as np\n",
    "\n",
    "freq_data, freq_label = prvi.get_frequencies('data/sst_train_raw.csv')\n",
    "text_vocab = prvi.Vocab(freq_data, max_size=-1, min_freq=1)\n",
    "label_vocab = prvi.Vocab(freq_label, use_extra=False)\n",
    "train_dataset = prvi.NLPDataset('data/sst_train_raw.csv', text_vocab, label_vocab)\n",
    "embedding_matrix = prvi.get_embedding_matrix(text_vocab, 300, 'data/sst_glove_6b_300d.txt')\n",
    "\n",
    "seed=7052020\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "model = drugi.BaselineModel(embedding_matrix)\n",
    "model.train_model(epochs=5, dataset=train_dataset, optimizer=torch.optim.Adam(model.get_params(), lr=1e-4), batch_size=10, text_vocab=text_vocab, label_vocab=label_vocab, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2200dfb3",
   "metadata": {},
   "source": [
    "# Zadatak 3. Implementacija povratne neuronske mreže (25% bodova)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f91736",
   "metadata": {},
   "source": [
    "Nakon što ste uspješno implementirali vaš baseline model, vrijeme je da isprobamo neki model baziran na povratnim neuronskim mrežama. Vaš zadatak je implementirati osnovni model povratne neuronske meže po izboru. Na izboru su vam iduće ćelije: [“Vanilla” RNN, GRU, LSTM].\n",
    "\n",
    "Za odabrani model, detaljno pročitajte njegovu dokumentaciju. U nastavku ćemo vam samo skrenuti pozornost na nekoliko bitnih detalja:\n",
    "\n",
    "- Svaka RNN mreža kao izlaz svoje forward metode vraća (1) niz skrivenih stanja posljednjeg sloja i (2) skriveno stanje (tj., skrivena stanja u slučaju LSTMa) za sve slojeve zadnjeg vremenskog koraka. Kao ulaz u dekoder obično želite staviti skriveno stanje iz zadnjeg sloja u zadnjem vremenskom koraku. Kod LSTMa, to je h komponenta dualnog (h, c) skrivenog stanja.\n",
    "\n",
    "- Radi brzine, RNN mreže preferiraju inpute u time-first formatu (budući da je brže iterirati po prvoj dimenziji tenzora). Transponirajte ulaze prije nego ih šaljete RNN ćeliji.\n",
    "\n",
    "- Tenzori koji su ulaz u RNN ćelije se često “pakiraju”. Pakiranje je zapis tenzora kojemu su pridružene stvarne duljine svakog elementa u batchu. Ako koristite pakiranje, RNN mreža se neće odmatati za vremenske korake koji sadrže padding u elementima batcha. Ovdje osim efikasnosti možete dobiti i na preciznosti, ali ovaj dio nije nužan dio vaše implementacije.\n",
    "\n",
    "- Implementirajte gradient clipping prije optimizacijskog koraka Osnovni model vaše odabrane RNN ćelije treba izgledati ovako:\n",
    "\n",
    "        rnn(150) -> rnn(150) -> fc(150, 150) -> ReLU() -> fc(150,1)\n",
    "    \n",
    "Vaš osnovni model RNN ćelije bi trebao biti jednosmjeran i imati dva sloja. Za višeslojni RNN iskoristite argument num_layers pri konstrukciji RNN mreže."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15ec4056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 results on validation dataset:\n",
      "Accuracy: 0.7243272926963207\n",
      "Precision: 0.6749146757679181\n",
      "F1 score: 0.7591170825335892\n",
      "Loss: 0.65754557\n",
      "Confusion matrix:\n",
      " [[528 381]\n",
      " [121 791]]\n",
      "\n",
      "Epoch 2 results on validation dataset:\n",
      "Accuracy: 0.7237781438769907\n",
      "Precision: 0.6691480562448304\n",
      "F1 score: 0.7628477133427629\n",
      "Loss: 0.66014284\n",
      "Confusion matrix:\n",
      " [[509 400]\n",
      " [103 809]]\n",
      "\n",
      "Epoch 3 results on validation dataset:\n",
      "Accuracy: 0.6968698517298187\n",
      "Precision: 0.6325478645066274\n",
      "F1 score: 0.756828193832599\n",
      "Loss: 0.6834572\n",
      "Confusion matrix:\n",
      " [[410 499]\n",
      " [ 53 859]]\n",
      "\n",
      "Epoch 4 results on validation dataset:\n",
      "Accuracy: 0.7380560131795717\n",
      "Precision: 0.6772616136919315\n",
      "F1 score: 0.7769985974754559\n",
      "Loss: 0.6542361\n",
      "Confusion matrix:\n",
      " [[513 396]\n",
      " [ 81 831]]\n",
      "\n",
      "Epoch 5 results on validation dataset:\n",
      "Accuracy: 0.7556287753981329\n",
      "Precision: 0.7097933513027853\n",
      "F1 score: 0.7802469135802469\n",
      "Loss: 0.637965\n",
      "Confusion matrix:\n",
      " [[586 323]\n",
      " [122 790]]\n",
      "\n",
      "Results on test dataset:\n",
      "Accuracy: 0.7557339449541285\n",
      "Precision: 0.6972477064220184\n",
      "F1 score: 0.7810894141829394\n",
      "Loss: 0.6385986\n",
      "Confusion matrix:\n",
      " [[279 165]\n",
      " [ 48 380]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import treci\n",
    "\n",
    "freq_data, freq_label = prvi.get_frequencies('data/sst_train_raw.csv')\n",
    "text_vocab = prvi.Vocab(freq_data, max_size=-1, min_freq=1)\n",
    "label_vocab = prvi.Vocab(freq_label, use_extra=False)\n",
    "train_dataset = prvi.NLPDataset('data/sst_train_raw.csv', text_vocab, label_vocab)\n",
    "valid_dataset = prvi.NLPDataset('data/sst_valid_raw.csv', text_vocab, label_vocab)\n",
    "test_dataset = prvi.NLPDataset('data/sst_test_raw.csv', text_vocab, label_vocab)\n",
    "embedding_matrix = prvi.get_embedding_matrix(text_vocab, 'data/sst_glove_6b_300d.txt', 300)\n",
    "\n",
    "model = treci.MyModel(embedding_matrix, text_vocab, label_vocab)\n",
    "model.train_model(epochs=5, train_dataset=train_dataset, valid_dataset=valid_dataset, test_dataset=test_dataset, optimizer=torch.optim.Adam(model.params, lr=1e-4), batch_size=10, grad_clip=0.25, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a015bc",
   "metadata": {},
   "source": [
    "# Zadatak 4. Usporedba modela i pretraga hiperparametara (25% bodova)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11829ddf",
   "metadata": {},
   "source": [
    "Usporedba RNN ćelija\n",
    "Neovisno o tome koju RNN ćeliju ste odabrali u trećem zadatku, proširite vaš kod na način da vrsta RNN ćelije bude argument. Pokrenite vaš kod za preostale vrste RNN ćelija i zapišite rezultate. Je li neka ćelija očiti pobjednik? Je li neka ćelija očiti gubitnik?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1a52ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cetvrti\n",
    "\n",
    "freq_data, freq_label = prvi.get_frequencies('data/sst_train_raw.csv')\n",
    "text_vocab = prvi.Vocab(freq_data, max_size=-1, min_freq=1)\n",
    "label_vocab = prvi.Vocab(freq_label, use_extra=False)\n",
    "train_dataset = prvi.NLPDataset('data/sst_train_raw.csv', text_vocab, label_vocab)\n",
    "valid_dataset = prvi.NLPDataset('data/sst_valid_raw.csv', text_vocab, label_vocab)\n",
    "test_dataset = prvi.NLPDataset('data/sst_test_raw.csv', text_vocab, label_vocab)\n",
    "embedding_matrix = prvi.get_embedding_matrix(text_vocab, 300, 'data/sst_glove_6b_300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d189bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy za RNN:0.7291284403669726\n",
      "Test accuracy za GRU:0.7344036697247707\n",
      "Test accuracy za LSTM:0.7589449541284404\n"
     ]
    }
   ],
   "source": [
    "net_types = ['RNN', 'GRU', 'LSTM']\n",
    "\n",
    "for net_type in net_types:\n",
    "    accs = list()\n",
    "    for i in range(5):\n",
    "        model = cetvrti.CustomRNNModel(embedding_matrix, text_vocab, label_vocab, net_type=net_type)\n",
    "        model.cuda()\n",
    "        acc = model.train_model(5, train_dataset, valid_dataset, test_dataset, optimizer = torch.optim.Adam(model.params, lr=1e-4), batch_size = 10, grad_clip = 0.25, verbose=False)\n",
    "        if acc > 0.55:\n",
    "            accs.append(acc)\n",
    "        else:\n",
    "            i -= 1\n",
    "    print('Test accuracy za ' + net_type + ':' + str(torch.mean(torch.tensor(accs)).item() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795c9afc",
   "metadata": {},
   "source": [
    "#### Komentar: \n",
    "Mreže u nekim slučajevima zapnu u lokalnom minimumu koji klasificira sve ulaze u istu klasu. U tim slučajevima vjerojatno samo nemamo sreće s inicijalizacijom težina. Accuracy je obično ispod 0.5 u toj situaciji pa te slučajeve nećemo uzeti u obzir kod računanja prosječnog accuracy-a.\n",
    "\n",
    "Vidimo da je prosječni accuracy LSTM-a bolji od ostalih vrsta RNNova."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5952ba54",
   "metadata": {},
   "source": [
    "Ponovite ovu usporedbu uz izmjenu hiperparametara povratnih neuronskih mreža. Idući hiperparametri povratnih neuronskih mreža su nam interesantni:\n",
    "\n",
    "    hidden_size\n",
    "    num_layers\n",
    "    dropout: primjenjen između uzastopnih slojeva RNNa (funkcionira samo za 2+ slojeva)\n",
    "    bidirectional: dimenzionalnost izlaza dvosmjerne rnn ćelije je dvostruka\n",
    "    \n",
    "Isprobajte barem 3 različite vrijednosti za svaki hiperparametar (osim bidirectional, koji ima samo dvije vrijednosti). Način na koji ćete kombinirati te vrijednosti je potpuno na vama (iscrpna rešetkasta pretraga je vremenski previše zahtjevna). Pokrenite svaku vrstu ćelije za svaku kombinaciju hiperparametara i zapišite rezultate (relevantne metrike). Nemojte se bojati raditi agresivne izmjene u vrijednostima hiperparametara (male izmjene vam neće dati puno informacija). Primjećujete li da neki hiperparametar bitno utječe na performanse ćelija? Koji?\n",
    "\n",
    "Zapamtite / zapišite set hiperparametara koji vam daje najbolje rezultate. Za njega pokrenite učenje barem 5 puta s različitim seedovima i zapišite dobivene metrike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09a255d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy za bidirectional=False, num_layers=2, hidden_size=100, dropout=0.2:0.7293577981651376\n",
      "Test accuracy za bidirectional=False, num_layers=2, hidden_size=100, dropout=0.5:0.7465596330275229\n",
      "Test accuracy za bidirectional=False, num_layers=2, hidden_size=100, dropout=0.8:0.7155963302752294\n",
      "Test accuracy za bidirectional=False, num_layers=2, hidden_size=150, dropout=0.2:0.7201834862385321\n",
      "Test accuracy za bidirectional=False, num_layers=2, hidden_size=150, dropout=0.5:0.7488532110091743\n",
      "Test accuracy za bidirectional=False, num_layers=2, hidden_size=150, dropout=0.8:0.7626146788990825\n",
      "Test accuracy za bidirectional=False, num_layers=2, hidden_size=200, dropout=0.2:0.7362385321100917\n",
      "Test accuracy za bidirectional=False, num_layers=2, hidden_size=200, dropout=0.5:0.7614678899082569\n",
      "Test accuracy za bidirectional=False, num_layers=2, hidden_size=200, dropout=0.8:0.7729357798165137\n",
      "Test accuracy za bidirectional=False, num_layers=3, hidden_size=100, dropout=0.2:0.7614678899082569\n",
      "Test accuracy za bidirectional=False, num_layers=3, hidden_size=100, dropout=0.5:0.7396788990825688\n",
      "Test accuracy za bidirectional=False, num_layers=3, hidden_size=100, dropout=0.8:0.7809633027522935\n",
      "Test accuracy za bidirectional=False, num_layers=3, hidden_size=150, dropout=0.2:0.7098623853211009\n",
      "Test accuracy za bidirectional=False, num_layers=3, hidden_size=150, dropout=0.5:0.7855504587155964\n",
      "Test accuracy za bidirectional=False, num_layers=3, hidden_size=150, dropout=0.8:0.7098623853211009\n",
      "Test accuracy za bidirectional=False, num_layers=3, hidden_size=200, dropout=0.2:0.7626146788990825\n",
      "Test accuracy za bidirectional=False, num_layers=3, hidden_size=200, dropout=0.5:0.7637614678899083\n",
      "Test accuracy za bidirectional=False, num_layers=3, hidden_size=200, dropout=0.8:0.7098623853211009\n",
      "Test accuracy za bidirectional=False, num_layers=4, hidden_size=100, dropout=0.2:0.783256880733945\n",
      "Test accuracy za bidirectional=False, num_layers=4, hidden_size=100, dropout=0.5:0.7603211009174312\n",
      "Test accuracy za bidirectional=False, num_layers=4, hidden_size=100, dropout=0.8:0.7672018348623854\n",
      "Test accuracy za bidirectional=False, num_layers=4, hidden_size=150, dropout=0.2:0.7155963302752294\n",
      "Test accuracy za bidirectional=False, num_layers=4, hidden_size=150, dropout=0.5:0.7545871559633027\n",
      "Test accuracy za bidirectional=False, num_layers=4, hidden_size=150, dropout=0.8:0.786697247706422\n",
      "Test accuracy za bidirectional=False, num_layers=4, hidden_size=200, dropout=0.2:0.7591743119266054\n",
      "Test accuracy za bidirectional=False, num_layers=4, hidden_size=200, dropout=0.5:0.6892201834862385\n",
      "Test accuracy za bidirectional=False, num_layers=4, hidden_size=200, dropout=0.8:0.7110091743119266\n",
      "Test accuracy za bidirectional=True, num_layers=2, hidden_size=100, dropout=0.2:0.7408256880733946\n",
      "Test accuracy za bidirectional=True, num_layers=2, hidden_size=100, dropout=0.5:0.7511467889908257\n",
      "Test accuracy za bidirectional=True, num_layers=2, hidden_size=100, dropout=0.8:0.7798165137614679\n",
      "Test accuracy za bidirectional=True, num_layers=2, hidden_size=150, dropout=0.2:0.7098623853211009\n",
      "Test accuracy za bidirectional=True, num_layers=2, hidden_size=150, dropout=0.5:0.7809633027522935\n",
      "Test accuracy za bidirectional=True, num_layers=2, hidden_size=150, dropout=0.8:0.7511467889908257\n",
      "Test accuracy za bidirectional=True, num_layers=2, hidden_size=200, dropout=0.2:0.7660550458715596\n",
      "Test accuracy za bidirectional=True, num_layers=2, hidden_size=200, dropout=0.5:0.7178899082568807\n",
      "Test accuracy za bidirectional=True, num_layers=2, hidden_size=200, dropout=0.8:0.7763761467889908\n",
      "Test accuracy za bidirectional=True, num_layers=3, hidden_size=100, dropout=0.2:0.7385321100917431\n",
      "Test accuracy za bidirectional=True, num_layers=3, hidden_size=100, dropout=0.5:0.7396788990825688\n",
      "Test accuracy za bidirectional=True, num_layers=3, hidden_size=100, dropout=0.8:0.7889908256880734\n",
      "Test accuracy za bidirectional=True, num_layers=3, hidden_size=150, dropout=0.2:0.7305045871559633\n",
      "Test accuracy za bidirectional=True, num_layers=3, hidden_size=150, dropout=0.5:0.7385321100917431\n",
      "Test accuracy za bidirectional=True, num_layers=3, hidden_size=150, dropout=0.8:0.7327981651376146\n",
      "Test accuracy za bidirectional=True, num_layers=3, hidden_size=200, dropout=0.2:0.7614678899082569\n",
      "Test accuracy za bidirectional=True, num_layers=3, hidden_size=200, dropout=0.5:0.7603211009174312\n",
      "Test accuracy za bidirectional=True, num_layers=3, hidden_size=200, dropout=0.8:0.7637614678899083\n",
      "Test accuracy za bidirectional=True, num_layers=4, hidden_size=100, dropout=0.2:0.7672018348623854\n",
      "Test accuracy za bidirectional=True, num_layers=4, hidden_size=100, dropout=0.5:0.7763761467889908\n",
      "Test accuracy za bidirectional=True, num_layers=4, hidden_size=100, dropout=0.8:0.7270642201834863\n",
      "Test accuracy za bidirectional=True, num_layers=4, hidden_size=150, dropout=0.2:0.7190366972477065\n",
      "Test accuracy za bidirectional=True, num_layers=4, hidden_size=150, dropout=0.5:0.7557339449541285\n",
      "Test accuracy za bidirectional=True, num_layers=4, hidden_size=150, dropout=0.8:0.7672018348623854\n",
      "Test accuracy za bidirectional=True, num_layers=4, hidden_size=200, dropout=0.2:0.7729357798165137\n",
      "Test accuracy za bidirectional=True, num_layers=4, hidden_size=200, dropout=0.5:0.7614678899082569\n",
      "Test accuracy za bidirectional=True, num_layers=4, hidden_size=200, dropout=0.8:0.7419724770642202\n"
     ]
    }
   ],
   "source": [
    "hidden_sizes = [100, 150, 200]\n",
    "num_layers = [2, 3, 4]\n",
    "bidirectionals = [False, True]\n",
    "dropouts = [0.2, 0.5, 0.8]\n",
    "\n",
    "for bidirectional in bidirectionals:\n",
    "    for num_layer in num_layers:\n",
    "        for hidden_size in hidden_sizes:\n",
    "            for dropout in dropouts:\n",
    "                accs = list()\n",
    "                for i in range(5):\n",
    "                    model = cetvrti.CustomRNNModel(embedding_matrix, text_vocab, label_vocab, net_type='LSTM', hidden_size=hidden_size, num_layers=num_layer, dropout=dropout, bidirectional=bidirectional)\n",
    "                    model.cuda()\n",
    "                    acc = model.train_model(5, train_dataset, valid_dataset, test_dataset, optimizer = torch.optim.Adam(model.params, lr=1e-4), batch_size = 10, grad_clip = 0.25, verbose=False)\n",
    "                if acc > 0.55:\n",
    "                    accs.append(acc)\n",
    "                else:\n",
    "                    i -= 1\n",
    "                print('Test accuracy za bidirectional=' + str(bidirectional) + ', num_layers=' + str(num_layer) + ', hidden_size=' + str(hidden_size) + ', dropout=' + str(dropout) + ':' + str(torch.mean(torch.tensor(accs)).item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7704ff",
   "metadata": {},
   "source": [
    "#### Komentar:\n",
    "Najbolji postignuti test accuracy je za model: bidirectional=True, num_layers=3, hidden_size=100, dropout=0.8.\n",
    "Međutim, rezultati su dosta stohastički, i teško je reći da je baš taj skup hiperparametara najbolji. Performanse modela dosta (možda previše) ovise o inicijalizaciji težina. \n",
    "\n",
    "Generalno, moguće je primijetiti da dvosmjerni modeli postižu bolje rezultate od jednosmjernih, što nije iznenađujuće. Veličina skrivenih slojeva ne igra preveliku ulogu, a dropout je generalno najbolji na 0.5 ili 0.8, dok je 0.2 premalo. Konačno, modeli s više slojeva unutar RNN ćelija postižu bolje rezultate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404c99d5",
   "metadata": {},
   "source": [
    "## Optimizacija hiperparametara"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aeaa3f",
   "metadata": {},
   "source": [
    "Probajte pokrenuti povratne neuronske mreže za najbolji set hiperparametara bez da koristite prednaučene vektorske reprezentacije. Probajte isto za vaš baseline model. Koji model više “pati” od gubitka prednaučenih reprezentacija?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0554f135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 results on validation dataset:\n",
      "Accuracy: 0.5096101043382757\n",
      "Precision: 0.5119196988707654\n",
      "F1 score: 0.4774722059684026\n",
      "Loss: 84.01261\n",
      "Confusion matrix:\n",
      " [[520 389]\n",
      " [504 408]]\n",
      "\n",
      "Epoch 2 results on validation dataset:\n",
      "Accuracy: 0.5260845689181768\n",
      "Precision: 0.5316946959896507\n",
      "F1 score: 0.4878338278931751\n",
      "Loss: 69.05018\n",
      "Confusion matrix:\n",
      " [[547 362]\n",
      " [501 411]]\n",
      "\n",
      "Epoch 3 results on validation dataset:\n",
      "Accuracy: 0.5447556287753982\n",
      "Precision: 0.5499398315282792\n",
      "F1 score: 0.5243832472748134\n",
      "Loss: 59.757473\n",
      "Confusion matrix:\n",
      " [[535 374]\n",
      " [455 457]]\n",
      "\n",
      "Epoch 4 results on validation dataset:\n",
      "Accuracy: 0.5557386051619989\n",
      "Precision: 0.5609467455621302\n",
      "F1 score: 0.539556061468412\n",
      "Loss: 53.77381\n",
      "Confusion matrix:\n",
      " [[538 371]\n",
      " [438 474]]\n",
      "\n",
      "Epoch 5 results on validation dataset:\n",
      "Accuracy: 0.5617792421746294\n",
      "Precision: 0.5705445544554455\n",
      "F1 score: 0.536046511627907\n",
      "Loss: 50.29901\n",
      "Confusion matrix:\n",
      " [[562 347]\n",
      " [451 461]]\n",
      "\n",
      "Results on test dataset:\n",
      "Accuracy: 0.5619266055045872\n",
      "Precision: 0.5575\n",
      "F1 score: 0.5386473429951691\n",
      "Loss: 47.300426\n",
      "Confusion matrix:\n",
      " [[267 177]\n",
      " [205 223]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = prvi.get_embedding_matrix(text_vocab, 300)\n",
    "\n",
    "model = drugi.BaselineModel(embedding_matrix)\n",
    "model.train_model(epochs=5, dataset=train_dataset, optimizer=torch.optim.Adam(model.get_params(), lr=1e-4), batch_size=10, text_vocab=text_vocab, label_vocab=label_vocab, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94aab302",
   "metadata": {},
   "source": [
    "Vidimo da je korištenje nasumičnih vektorskih reprezentacija dosta narušilo performanse Baseline modela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5459ae16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 results on validation dataset:\n",
      "Accuracy: 0.6408566721581549\n",
      "Precision: 0.65\n",
      "F1 score: 0.6309255079006773\n",
      "Loss: tensor(0.6787)\n",
      "Confusion matrix:\n",
      " [[608 301]\n",
      " [353 559]]\n",
      "\n",
      "Epoch 4 results on validation dataset:\n",
      "Accuracy: 0.6611751784733663\n",
      "Precision: 0.648539778449144\n",
      "F1 score: 0.6761154855643045\n",
      "Loss: tensor(0.6773)\n",
      "Confusion matrix:\n",
      " [[560 349]\n",
      " [268 644]]\n",
      "\n",
      "Epoch 5 results on validation dataset:\n",
      "Accuracy: 0.6919275123558485\n",
      "Precision: 0.6641721234798877\n",
      "F1 score: 0.7168096920747098\n",
      "Loss: tensor(0.6669)\n",
      "Confusion matrix:\n",
      " [[550 359]\n",
      " [202 710]]\n",
      "\n",
      "Results on test dataset:\n",
      "Accuracy: 0.6777522935779816\n",
      "Precision: 0.6421663442940039\n",
      "F1 score: 0.7026455026455026\n",
      "Loss: tensor(0.6728)\n",
      "Confusion matrix:\n",
      " [[259 185]\n",
      " [ 96 332]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6777522935779816"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = cetvrti.CustomRNNModel(embedding_matrix, text_vocab, label_vocab, net_type='LSTM', hidden_size=100, num_layers=3, dropout=0.8, bidirectional=True)\n",
    "model.cuda()\n",
    "model.train_model(5, train_dataset, valid_dataset, test_dataset, optimizer = torch.optim.Adam(model.params, lr=1e-4), batch_size = 10, grad_clip = 0.25, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d75c3f2",
   "metadata": {},
   "source": [
    "#### Komentar:\n",
    "Accuracy Baseline modela pao je sa 0.65 na 0.56. To je pogoršanje od 13.8%\n",
    "Accuracy RNN modela pao je sa 0.79 na 0.68. To je pogoršanje od 13.9%\n",
    "Pogoršanje je podjednako u oba modela. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17de8af4",
   "metadata": {},
   "source": [
    "Ulazne vektorske reprezentacije su jedan jako bitan hiperparametar, za koji u okviru laboratorijske vježbe imamo samo dvije vrijednosti – koristimo li ih ili ne. U analizi teksta su ulazne vektorske reprezentacije veoma velik dio uspješnosti algoritma. U ovom dijelu laboratorijske vježbe trebate odabrati barem 5 od idućih hiperparametara te provjeriti kako modeli funkcioniraju za njihove izmjene. Ako hiperparametar utječe i na baseline model, kao i povratnu neuronsku mrežu, pokrenite eksperimente na oba modela. Za ćeliju povratne neuronske mreže odaberite onu koja ostvaruje (po vama) bolje rezultate na prošlom dijelu vježbe.\n",
    "\n",
    "Za hiperparametre označene s nekim brojem zvjezdica (*), odaberite samo jedan od onih s istim brojem zvjezdica.\n",
    "\n",
    "Hiperparametri:\n",
    "\n",
    "    (*) Veličina vokabulara V\n",
    "    (*) Minimalna frekvencija riječi min_freq\n",
    "    (**) Stopa učenja\n",
    "    (**) Veličina batcha\n",
    "    Dropout\n",
    "    Broj slojeva\n",
    "    Dimenzionalnost skrivenih slojeva\n",
    "    Optimizacijski algoritam (probajte nešto osim Adama)\n",
    "    Funkcija nelinearnosti (u potpuno povezanim slojevima)\n",
    "    Iznos na koji se podrezuju vrijednosti gradijenata\n",
    "    Vrsta sažimanja (Baseline)\n",
    "    Zamrzavanje ulaznih vektorskih reprezentacije (argument freeze funkcije from_pretrained)\n",
    "    \n",
    "Za svaki od odabranih hiperparametara isprobajte barem tri njegove različite vrijednosti (osim ako je binaran). Rezultate eksperimenata zapisujte. Pokrenite baseline i povratni model s najboljim hiperparametrima barem 5 puta i zapišite prosjek i devijaciju svih praćenih metrika. Čini li vam se neki parametar kao najutjecajniji za uspjeh? Nemojte se bojati raditi agresivne izmjene u vrijednostima hiperparametara jer će vas one lakše dovesti do zaključaka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "069c814e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy za max_size=300: 0\n",
      "Accuracy za max_size=500: 0.6857798165137615\n",
      "Accuracy za max_size=800: 0.7006880733944955\n",
      "Accuracy za batch_size=8: 0.7362385321100917\n",
      "Accuracy za batch_size=32: 0.7396788990825688\n",
      "Accuracy za batch_size=128: 0\n",
      "Accuracy za hidden_size=20: 0\n",
      "Accuracy za hidden_size=100: 0.7580275229357798\n",
      "Accuracy za hidden_size=300: 0.7534403669724771\n",
      "Accuracy za grad_clip=-0.5: 0.4908256880733945\n",
      "Accuracy za grad_clip=0.5: 0.7339449541284404\n",
      "Accuracy za grad_clip=5: 0.7213302752293578\n",
      "Accuracy za dropout=0.5: 0.7465596330275229\n",
      "Accuracy za dropout=0.7: 0.7637614678899083\n",
      "Accuracy za dropout=0.9: 0.7247706422018348\n"
     ]
    }
   ],
   "source": [
    "# model.train_model(5, train_dataset, valid_dataset, test_dataset, optimizer = torch.optim.Adam(model.params, lr=1e-4), batch_size = 10, grad_clip = 0.25, verbose=True)\n",
    "\n",
    "# uzet ćemo najbolji model do sad\n",
    "# bidirectional=True, num_layers=3, hidden_size=100, dropout=0.8\n",
    "velicine_vokabulara = [300, 500, 800]\n",
    "batch_sizes = [8, 32, 128]\n",
    "hidden_sizes = [20, 100, 300]\n",
    "grad_clips = [-0.5, 0.5, 5]\n",
    "dropouts = [0.5, 0.7, 0.9]\n",
    "\n",
    "for velicina in velicine_vokabulara:\n",
    "    freq_data, freq_label = prvi.get_frequencies('data/sst_train_raw.csv')\n",
    "    text_vocab = prvi.Vocab(freq_data, max_size=velicina, min_freq=1)\n",
    "    label_vocab = prvi.Vocab(freq_label, use_extra=False)\n",
    "    train_dataset = prvi.NLPDataset('data/sst_train_raw.csv', text_vocab, label_vocab)\n",
    "    valid_dataset = prvi.NLPDataset('data/sst_valid_raw.csv', text_vocab, label_vocab)\n",
    "    test_dataset = prvi.NLPDataset('data/sst_test_raw.csv', text_vocab, label_vocab)\n",
    "    embedding_matrix = prvi.get_embedding_matrix(text_vocab, 300, 'data/sst_glove_6b_300d.txt')\n",
    "    model = cetvrti.CustomRNNModel(embedding_matrix, text_vocab, label_vocab, net_type='LSTM', hidden_size=100, num_layers=3, dropout=0.8, bidirectional=True)\n",
    "    model.cuda()\n",
    "    acc = model.train_model(5, train_dataset, valid_dataset, test_dataset, optimizer = torch.optim.Adam(model.params, lr=1e-4), batch_size = 10, grad_clip = 0.25, verbose=False)\n",
    "    print('Accuracy za max_size=' + str(velicina) + ': ' + str(acc))\n",
    "    \n",
    "freq_data, freq_label = prvi.get_frequencies('data/sst_train_raw.csv')\n",
    "text_vocab = prvi.Vocab(freq_data, max_size=-1, min_freq=1)\n",
    "label_vocab = prvi.Vocab(freq_label, use_extra=False)\n",
    "train_dataset = prvi.NLPDataset('data/sst_train_raw.csv', text_vocab, label_vocab)\n",
    "valid_dataset = prvi.NLPDataset('data/sst_valid_raw.csv', text_vocab, label_vocab)\n",
    "test_dataset = prvi.NLPDataset('data/sst_test_raw.csv', text_vocab, label_vocab)\n",
    "embedding_matrix = prvi.get_embedding_matrix(text_vocab, 300, 'data/sst_glove_6b_300d.txt')\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    model = cetvrti.CustomRNNModel(embedding_matrix, text_vocab, label_vocab, net_type='LSTM', hidden_size=100, num_layers=3, dropout=0.8, bidirectional=True)\n",
    "    model.cuda()\n",
    "    acc = model.train_model(5, train_dataset, valid_dataset, test_dataset, optimizer = torch.optim.Adam(model.params, lr=1e-4), batch_size = batch_size, grad_clip = 0.25, verbose=False)\n",
    "    print('Accuracy za batch_size=' + str(batch_size) + ': ' + str(acc))\n",
    "    \n",
    "for hidden_size in hidden_sizes:\n",
    "    model = cetvrti.CustomRNNModel(embedding_matrix, text_vocab, label_vocab, net_type='LSTM', hidden_size=hidden_size, num_layers=3, dropout=0.8, bidirectional=True)\n",
    "    model.cuda()\n",
    "    acc = model.train_model(5, train_dataset, valid_dataset, test_dataset, optimizer = torch.optim.Adam(model.params, lr=1e-4), batch_size = 10, grad_clip = 0.25, verbose=False)\n",
    "    print('Accuracy za hidden_size=' + str(hidden_size) + ': ' + str(acc))\n",
    "    \n",
    "for grad_clip in grad_clips:\n",
    "    model = cetvrti.CustomRNNModel(embedding_matrix, text_vocab, label_vocab, net_type='LSTM', hidden_size=100, num_layers=3, dropout=0.8, bidirectional=True)\n",
    "    model.cuda()\n",
    "    acc = model.train_model(5, train_dataset, valid_dataset, test_dataset, optimizer = torch.optim.Adam(model.params, lr=1e-4), batch_size = 10, grad_clip = grad_clip, verbose=False)\n",
    "    print('Accuracy za grad_clip=' + str(grad_clip) + ': ' + str(acc))\n",
    "    \n",
    "for dropout in dropouts:\n",
    "    model = cetvrti.CustomRNNModel(embedding_matrix, text_vocab, label_vocab, net_type='LSTM', hidden_size=100, num_layers=3, dropout=dropout, bidirectional=True)\n",
    "    model.cuda()\n",
    "    acc = model.train_model(5, train_dataset, valid_dataset, test_dataset, optimizer = torch.optim.Adam(model.params, lr=1e-4), batch_size = 10, grad_clip = 0.25, verbose=False)\n",
    "    print('Accuracy za dropout=' + str(dropout) + ': ' + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94349196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
