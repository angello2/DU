{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39b9f833",
   "metadata": {},
   "source": [
    "# Zadatak 1. Učitavanje podataka (25% bodova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c11f4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prvi\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3610b7f1",
   "metadata": {},
   "source": [
    "Sve metode potrebne za prvi zadatak nalaze se u datoteci prvi.py. U sljedećem isječku koda računamo frekvencije pojavljivanja riječi, stvaramo vokabulare i učitavamo dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10cdf32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_data, freq_label = prvi.get_frequencies('data/sst_train_raw.csv')\n",
    "text_vocab = prvi.Vocab(freq_data, max_size=-1, min_freq=1)\n",
    "label_vocab = prvi.Vocab(freq_label, use_extra=False)\n",
    "train_dataset = prvi.NLPDataset('data/sst_train_raw.csv', vocab_data, vocab_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae3c761",
   "metadata": {},
   "source": [
    "## Razred Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca00d897",
   "metadata": {},
   "source": [
    "Vaša implementacija razreda Vocab mora implementirati funkcionalnost pretvorbe niza tokena (ili jednog tokena) u brojeve. Ovu funkciju možete nazvati encode. Primjer ove pretvorbe za četvrtu instancu train skupa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "039dde27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: ['yet', 'the', 'act', 'is', 'still', 'charming', 'here']\n",
      "Label: positive\n",
      "Numericalized text: tensor([189,   2, 674,   7, 129, 348, 143])\n",
      "Numericalized label: tensor([0])\n"
     ]
    }
   ],
   "source": [
    "instance_text, instance_label = train_dataset.instances[3]\n",
    "print(f\"Text: {instance_text}\")\n",
    "print(f\"Label: {instance_label}\")\n",
    "print(f\"Numericalized text: {text_vocab.encode(instance_text)}\")\n",
    "print(f\"Numericalized label: {label_vocab.encode(instance_label)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cff3bc",
   "metadata": {},
   "source": [
    "Također, vaša implementacija razreda Vocab mora primati iduće parametre:\n",
    "\n",
    "max_size: maksimalni broj tokena koji se sprema u vokabular (uključuje i posebne znakove). -1 označava da se spremaju svi tokeni.\n",
    "min_freq: minimalna frekvencija koju token mora imati da bi ga se spremilo u vokabular (\\ge). Posebni znakovi ne prolaze ovu provjeru.\n",
    "Primjer izgradnje vokabulara sa svim tokenima (duljina uključuje i posebne znakove):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8e3e365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14806\n"
     ]
    }
   ],
   "source": [
    "text_vocab = prvi.Vocab(freq_data, max_size=-1, min_freq=0)\n",
    "print(len(text_vocab.itos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068bb1c9",
   "metadata": {},
   "source": [
    "## Učitavanje vektorskih reprezentacija"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f01bcd",
   "metadata": {},
   "source": [
    "Vaš zadatak je implementirati funkciju koja će za zadani vokabular (iterable stringova) generirati embedding matricu. Vaša funkcija treba podržavati dva načina genriranja embedding matrice: nasumična inicijalizacija iz standardne normalne razdiobe (N(0,1)) i učitavanjem iz datoteke. Pri učitavanju iz datoteke, ako ne pronađete vektorsku reprezentaciju za neku riječ, inicijalizirajte ju normalno. Vektorsku reprezentaciju za znak punjenja (na indeksu 0) morate inicijalizirati na vektor nula. Jednostavan način na koji možete implementirati ovo učitavanje je da inicijalirate matricu iz standardne normalne razdiobe, a potom prebrišete inicijalnu reprezentaciju u retku za svaku riječ koju učitate. Bitno: Pripazite da redoslijed vektorskih reprezentacija u matrici odgovara redoslijedu riječi u vokabularu! Npr., na indeksu 0 mora biti reprezentacija za posebni znak punjenja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec5a2f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14806, 300])\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = prvi.get_embedding_matrix(vocab_data, 'data/sst_glove_6b_300d.txt', 300)\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c9e1f2",
   "metadata": {},
   "source": [
    "Jednom kad ste uspješno učitali vašu V×d embedding matricu, iskoristite torch.nn.Embedding.from_pretrained() kako bi vašu matricu spremili u optimizirani omotač za vektorske reprezentacije. Postavite parametar funkcije padding_idx na 0 (indeks znaka punjenja u vašoj embedding matrici), a parametar funkcije freeze ostavite na True ako koristite predtrenirane reprezentacije, a postavite na False inače."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbb81ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "716ffd6d",
   "metadata": {},
   "source": [
    "## Nadjačavanje metoda torch.utils.data.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580bfc94",
   "metadata": {},
   "source": [
    "Da bi naša implementacija razreda NLPDataset bila potpuna, potrebno je nadjačati __getitem__ metodu koja omogućava indeksiranje razreda. Za potrebe vježbe, ta metoda treba vraćati numerikalizirani text i labelu referencirane instance. Također, dovoljno je napraviti da se numerikalizacija radi “on-the-fly”, i nije ju nužno cachirati.\n",
    "\n",
    "Primjer numerikalizacije s nadjačavanjem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66ad28de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: ['yet', 'the', 'act', 'is', 'still', 'charming', 'here']\n",
      "Label: positive\n",
      "Numericalized text: tensor([189,   2, 674,   7, 129, 348, 143])\n",
      "Numericalized label: tensor([0])\n"
     ]
    }
   ],
   "source": [
    "instance_text, instance_label = train_dataset.instances[3]\n",
    "print(f\"Text: {instance_text}\")\n",
    "print(f\"Label: {instance_label}\")\n",
    "numericalized_text, numericalized_label = train_dataset[3]\n",
    "print(f\"Numericalized text: {numericalized_text}\")\n",
    "print(f\"Numericalized label: {numericalized_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0d0aa4",
   "metadata": {},
   "source": [
    "# Implementacija batchiranja podataka: collate funkcija"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424dc981",
   "metadata": {},
   "source": [
    "Zadatak naše collate funkcije biti će nadopuniti duljine instanci znakom punjenja do duljine najdulje instance u batchu. Za ovo, pogledajte funkciju from torch.nn.utils.rnn.pad_sequence. Primjetite da vaša implementacija collate funkcije mora znati koji se indeks koristi kao znak punjenja.\n",
    "\n",
    "Jednom kad smo implementirali sve navedeno, naše učitavanje podataka bi moglo izgledati ovako:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18f0a443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts: tensor([[   2,  554,    7, 2872,    6,   22,    2, 2873, 1236,    8,   96, 4800,\n",
      "            4,   10,   72,    8,  242,    6,   75,    3, 3576,   56, 3577,   34,\n",
      "         2022, 2874, 7123, 3578, 7124,   42,  779, 7125,    0,    0],\n",
      "        [   2, 2875, 2023, 4801,    5,    2, 3579,    5,    2, 2876, 4802,    7,\n",
      "           40,  829,   10,    3, 4803,    5,  627,   62,   27, 2877, 2024, 4804,\n",
      "          962,  715,    8, 7126,  555,    5, 7127, 4805,    8, 7128]])\n",
      "Labels: tensor([0, 0])\n",
      "Lengths: tensor([32, 34])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2 # Only for demonstrative purposes\n",
    "shuffle = False # Only for demonstrative purposes\n",
    "train_data_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, \n",
    "                              shuffle=shuffle, collate_fn=prvi.pad_collate_fn)\n",
    "texts, labels, lengths = next(iter(train_data_loader))\n",
    "print(f\"Texts: {texts}\")\n",
    "print(f\"Labels: {labels}\")\n",
    "print(f\"Lengths: {lengths}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6755d6",
   "metadata": {},
   "source": [
    "# Zadatak 2. Implementacija baseline modela (25% bodova)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285baf5d",
   "metadata": {},
   "source": [
    "Prvi korak kod svakog zadatka strojnog učenja bi trebao biti implementacija baseline modela. Baseline model nam služi za procjenu performansi koje naš stvarni, uobičajeno skuplji model mora moći preći kao plitak potok. Također, baseline modeli će nam pokazati kolika je stvarno cijena izvođenja naprednijih modela.\n",
    "\n",
    "Vaš zadatak u laboratorijskoj vježbi je implementirati model koji će koristiti sažimanje usrednjavanjem (eng. mean pooling) kako bi eliminirao problematičnu varijabilnu dimenziju. Pri primjeni sažimanja usrednjavanjem odmah eliminirajte cijelu vremensku dimenziju (tzv. okno je veličine T).\n",
    "\n",
    "Osnovni model koji implementirate mora izgledati ovako:\n",
    "\n",
    "    avg_pool() -> fc(300, 150) -> ReLU() -> fc(150, 150) -> ReLU() -> fc(150,1)\n",
    "    \n",
    "Kao gubitak predlažemo da koristite BCEWithLogitsLoss, u kojem slučaju ne morate primjeniti sigmoidu na izlaznim logitima. Alternativno, možete staviti da vam je izlazna dimenzionalnost broj klasa te koristiti gubitak unakrsne entropije. Oba pristupa su korištena u praksi ovisno o osobnim preferencama.\n",
    "\n",
    "Kao algoritam optimizacije koristite Adam.\n",
    "\n",
    "Implementirajte metrike praćenja performansi modela. Osim gubitka na skupu podataka, zanimaju nas preciznost (eng. accuracy), f1 mjera i matrica zabune (eng. confusion matrix). Nakon svake epohe ispišite performanse modela po svim metrikama na skupu za validaciju, a nakon zadnje epohe ispišite performanse modela na skupu za testiranje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bb6007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
